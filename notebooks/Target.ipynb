{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Aquisition and Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadImage(path):\n",
    "    image = cv2.imread(path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BGR = 0\n",
    "HSV = 1\n",
    "BW  = 2\n",
    "def displayImage(input_image, type):\n",
    "    if type == 0: # BGR\n",
    "        plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "    elif type == 1: # HSV\n",
    "        plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_HSV2RGB))\n",
    "    else: # B&W\n",
    "        plt.imshow(input_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def performRange(input_image, lower, upper):\n",
    "    return cv2.inRange(input_image, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = loadImage(\"../2016_RealFullField/20.jpg\")\n",
    "displayImage(image, BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an inRange operation using HSV\n",
    "We are going to convert our BGR image to the [HSV color space](https://en.wikipedia.org/wiki/HSL_and_HSV) and then select just the image pixels that fall in-between two colors. Since we are looking for a specific reflected greenish color we can use a fairly narrow Hue range (85-95 in our case) and accomodate a large range for saturation and value/brightness (100-255 in our case). This is usually harder to achieve with BGR images since all three channels change together with the amount of light in the image.\n",
    "\n",
    "Blurring the image is often used to remove small features we're not interested in (noise). We'll compare our result with and without blurring the image first.\n",
    " \n",
    "### HSV lower and upper limits\n",
    "Select a lower and upper HSV bound color for the **inRange** operation and display these colors next to the to the target image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hsv_lower = (85, 100, 100)\n",
    "hsv_upper = (105, 255, 255)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(np.uint8([[hsv_lower]*100]*100), cv2.COLOR_HSV2RGB))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv2.cvtColor(image[:300, 200:500], cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(np.uint8([[hsv_upper]*100]*100), cv2.COLOR_HSV2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inRange without blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "ranged_image = cv2.inRange(hsv_image, hsv_lower, hsv_upper)\n",
    "displayImage(ranged_image, BW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inRange with blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blurred_hsv_image = cv2.blur(hsv_image, (3, 3))\n",
    "ranged_image = cv2.inRange(blurred_hsv_image, hsv_lower, hsv_upper)\n",
    "displayImage(ranged_image, BW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Noise Removal\n",
    "[Morphological Closing](https://en.wikipedia.org/wiki/Closing_%28morphology%29) is dilation followed by erosion and is used for closing small holes. Blurring did a good job removing these holes in our particular scenario, so it is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def performClosing(input_image, size=1):\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, (size, size))\n",
    "    output_image = cv2.dilate(input_image, element)\n",
    "    return cv2.erode(output_image, element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closed_image = performClosing(ranged_image, size=2)\n",
    "displayImage(closed_image, BW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Morphological Opening](https://en.wikipedia.org/wiki/Opening_%28morphology%29) is erosion followed by dilation and is used for removing small objects. Our target is so much larger than the noise present that this is probably not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def performOpening(input_image, size=1):\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, (size, size))\n",
    "    output_image = cv2.erode(input_image, element)\n",
    "    return cv2.dilate(output_image, element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opened_image = performOpening(ranged_image, size=14) # 14 is pretty extreme\n",
    "displayImage(opened_image, BW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Features of Interest\n",
    "A simple test is to find the bounding box of the largest contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findTarget(image, mask, overlay=0):\n",
    "    image = image.copy()\n",
    "    mask = mask.copy()\n",
    "    _, contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # check to see if any contours were found\n",
    "    if len(contours) > 0:\n",
    "        # sort the contours and find the largest one\n",
    "        target = sorted(contours, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        if overlay == 0:\n",
    "            # compute the bounding box and draw it\n",
    "            box = np.int32(cv2.boxPoints(cv2.minAreaRect(target)))\n",
    "            cv2.drawContours(image, [box], -1, (0, 0, 255), 1)\n",
    "        else:\n",
    "            # draw the contour\n",
    "            cv2.drawContours(image, [target], -1, (0, 0, 255), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "marked_image = findTarget(image, ranged_image, 1)\n",
    "displayImage(marked_image, BGR)\n",
    "    \n",
    "# zoom in\n",
    "displayImage(marked_image[150:200, 250:300], BGR)\n",
    "displayImage(marked_image[150:200, 425:475], BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displaySamples(samples):\n",
    "    for img in [\"../2016_RealFullField/{}.jpg\".format(i) for i in samples]:\n",
    "        image = loadImage(img)\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        blurred_hsv_image = cv2.blur(hsv_image, (3, 3))\n",
    "        ranged_image = cv2.inRange(blurred_hsv_image, hsv_lower, hsv_upper)\n",
    "        marked_image = findTarget(image, ranged_image, 1)\n",
    "\n",
    "        print(img)\n",
    "        displayImage(marked_image, BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Target in FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "displaySamples(itertools.chain([9], range(13, 17), range(19, 34)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Targets in FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "displaySamples(itertools.chain([0], range(3, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
